Инфраструктура ELK включает следующие компоненты:<br/>
<p><img style="display: block; margin-left: auto; margin-right: auto;" title="Prometheus" src="images/elk_use/structure_elk.png"
        alt="Структура ELK" width="993" height="403"/></p>
<hr id="system-readmore" />
<ul>
    <li><b>FileBeat</b> – агент на серверах для отправки различных типов оперативных данных в Elasticsearch.</li>
    <li><b>Logstash</b> — средство сбора, преобразования и сохранения в общем хранилище событий из файлов, баз данных, логов и других источников в реальном времени.  Logsatsh позволяет модифицировать полученные данные с помощью фильтров: разбить строку на поля, обогатить или их, агрегировать несколько строк, преобразовать их в JSON-документы и пр. Обработанные данные Logsatsh отправляет в системы-потребители.</li>
    <li><b>Elasticsearch</b> – масштабируемая утилита полнотекстового поиска и аналитики, которая позволяет быстро в режиме реального времени хранить, искать и анализировать большие объемы данных. Как правило, ES используется в качестве NoSQL-базы данных для приложений со сложными функциями поиска. Elasticsearch основана на библиотеке Apache Lucene, предназначенной для индексирования и поиска информации в любом типе документов. В масштабных Big Data системах несколько копий Elasticsearch объединяются в кластер.</li>
    <li><b>Kibana</b> – визуальный инструмент для Elasticsearch, чтобы взаимодействовать с данными, которые хранятся в индексах ES. Веб-интерфейс Kibana позволяет быстро создавать и обмениваться динамическими панелями мониторинга, включая таблицы, графики и диаграммы, которые отображают изменения в ES-запросах в реальном времени. Примечательно, что изначально Kibana была ориентирована на работу с Logstash, а не на Elasticsearch. Однако, с интеграцией 3-х систем в единую ELK-платформу, Kibana стала работать непосредственно с ES.</li>
</ul>
В рамках единой ELK-платформы все вышеперечисленные компоненты взаимодействуют следующим образом:<br/>
Logstash представляет собой конвейер обработки данных (data pipeline) на стороне сервера, который одновременно получает данные из нескольких источников, включая FileBeat. Здесь выполняется первичное преобразование, фильтрация, агрегация или парсинг логов, а затем обработанные данные отправляется в Elasticsearch.<br/>
Elasticsearch играет роль ядра всей системы, сочетая функции базы данных, поискового и аналитического движков. Быстрый и гибкий поиск обеспечивается за счет анализаторов текста, нечеткого поиска, поддержки восточных языков (корейский, китайский, японский). Наличие REST API позволяет добавлять, просматривать, модифицировать и удалять данные [3].<br/>
Kibana позволяет визуализировать данные ES, а также администрировать базу данных.<br/>
<br/>
Зачем все то разработчику? Типичный ответ для анализа логов, но это слишком узко. В одной компании удалось использовать ELK для анализа продаж и мониторинга цен конкурентов. В другой компании, поиск по справочнику товаров (~300 000 наименований в виде файлов структурированных по каталогам).<br/>
<br/>
<b>Ссылки:</b><br/>
<a style="text-decoration: underline; color: #3366ff;" href="https://bigdataschool.ru/blog/what-is-elk.html" target="_blank" rel="noopener noreferrer">Зачем вам Elasticsearch: полнотекстовый поиск по Big Data</a><br/>
<a style="text-decoration: underline; color: #3366ff;" href="https://habr.com/ru/companies/uteam/articles/278729/" target="_blank" rel="noopener noreferrer">Kibana-мать или Зачем вам вообще нужны логи? (2016 г.)</a><br/>
<a style="text-decoration: underline; color: #3366ff;" href="https://v.perm.ru/index.php/instrumenty-devops/elasticsearch-linux" target="_blank" rel="noopener noreferrer">Установка ElasticSearch в Linux</a><br/>
